{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coded by Lujia Zhong @lujiazho<br>\n",
    "Reference: https://github.com/facebookresearch/detr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.ops.boxes import box_area\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "################################################################################################\n",
    "#                                       Transformer Part                                       #\n",
    "################################################################################################\n",
    "\n",
    "def padding_mask(seq_q_shape, seq_k):\n",
    "    B, len_q = seq_q_shape\n",
    "    B, len_k = seq_k.shape\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # 0 is padding\n",
    "    return pad_attn_mask.expand(B, len_q, len_k)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.d_key = config.d_key\n",
    "        self.d_value = config.d_value\n",
    "        self.n_heads = config.n_heads\n",
    "        \n",
    "        self.W_Q = nn.Linear(config.d_model, self.d_key * self.n_heads)\n",
    "        self.W_K = nn.Linear(config.d_model, self.d_key * self.n_heads)\n",
    "        self.W_V = nn.Linear(config.d_model, self.d_value * self.n_heads)\n",
    "        \n",
    "        self.linear = nn.Linear(self.n_heads * self.d_value, config.d_model)\n",
    "        self.layer_norm = nn.LayerNorm(config.d_model)\n",
    "        \n",
    "        self.attn_dropout = nn.Dropout(config.dropout_rate)\n",
    "        self.proj_dropout = nn.Dropout(config.dropout_rate)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask, posemb, queries):\n",
    "        residual, batch_size = Q, Q.shape[0]\n",
    "        \n",
    "        if posemb is not None and queries is not None: # MA\n",
    "            Q = Q + queries\n",
    "            K = K + posemb\n",
    "        elif posemb is not None: # encoder MSA, Q == K\n",
    "            Q = K = (Q + posemb)\n",
    "        else: # decoder MSA, Q == K\n",
    "            Q = K = (Q + queries)\n",
    "        \n",
    "        query_layer = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_key).transpose(1,2)\n",
    "        key_layer = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_key).transpose(1,2)\n",
    "        value_layer = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_value).transpose(1,2)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2)) / (self.d_key**0.5)\n",
    "        if attn_mask is not None:\n",
    "            # expand in heads' dimension\n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "            attention_scores.masked_fill_(attn_mask, -1e9) # masked_fill_: 1 masked, 0 unmasked\n",
    "        \n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "        attention_probs = self.attn_dropout(attention_probs)\n",
    "        \n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.transpose(1, 2)\n",
    "        context_layer = context_layer.contiguous().view(batch_size, -1, self.n_heads*self.d_value)\n",
    "        \n",
    "        attention_output = self.linear(context_layer)\n",
    "        attention_output = self.proj_dropout(attention_output)\n",
    "        \n",
    "        return self.layer_norm(attention_output + residual), attention_probs\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(config.d_model, config.d_mlp)\n",
    "        self.fc2 = nn.Linear(config.d_mlp, config.d_model)\n",
    "        self.layer_norm = nn.LayerNorm(config.d_model)\n",
    "        self.dropout = nn.Dropout(config.dropout_rate)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
    "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        residual = inputs\n",
    "        \n",
    "        output = nn.ReLU()(self.fc1(inputs))\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        output = self.fc2(output)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        return self.layer_norm(output + residual)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(config)\n",
    "        self.ffn = MLP(config)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask, posemb):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, \n",
    "                                               enc_self_attn_mask, posemb, None)\n",
    "        \n",
    "        enc_outputs = self.ffn(enc_outputs)\n",
    "        \n",
    "        return enc_outputs, attn\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(config)\n",
    "        self.dec_enc_attn = MultiHeadAttention(config)\n",
    "        self.ffn = MLP(config)\n",
    "\n",
    "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_pad_mask, dec_enc_attn_pad_mask, posemb, queries):\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, \n",
    "                                                        dec_self_attn_pad_mask, None, queries)\n",
    "        \n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, \n",
    "                                                      dec_enc_attn_pad_mask, posemb, queries)\n",
    "        \n",
    "        dec_outputs = self.ffn(dec_outputs)\n",
    "        \n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs, mask, posemb):\n",
    "        enc_outputs = enc_inputs\n",
    "\n",
    "        enc_self_attn_mask = padding_mask(mask.shape, mask)\n",
    "\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask, posemb)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        \n",
    "        return enc_outputs, enc_self_attns\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.n_layers)])\n",
    "\n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs, mask, posemb, queries):\n",
    "        dec_outputs = dec_inputs\n",
    "\n",
    "        dec_enc_attn_pad_mask = padding_mask(dec_inputs.shape[:-1], mask)\n",
    "\n",
    "        intermediate = []\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, None, \n",
    "                                                             dec_enc_attn_pad_mask, posemb, queries)\n",
    "            intermediate.append(dec_outputs)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        \n",
    "        return torch.stack(intermediate), dec_self_attns, dec_enc_attns\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_inputs, mask, posemb, queries):\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs, mask, posemb)\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs, \n",
    "                                                                  mask, posemb, queries)\n",
    "        \n",
    "        return dec_outputs, enc_self_attns, dec_self_attns, dec_enc_attns\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#                                         Resnet Part                                          #\n",
    "################################################################################################\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * 4, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * 4),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * 4:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * 4, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * 4)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU()(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, stride=2, kernel_size=7, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.conv2_x = self.conv_layer(config.block, 64, config.num_block[0], ini_stride=1)\n",
    "        self.conv3_x = self.conv_layer(config.block, 128, config.num_block[1], ini_stride=2)\n",
    "        self.conv4_x = self.conv_layer(config.block, 256, config.num_block[2], ini_stride=2)\n",
    "        self.conv5_x = self.conv_layer(config.block, 512, config.num_block[3], ini_stride=2)\n",
    "\n",
    "    def conv_layer(self, block, out_channels, num_blocks, ini_stride):\n",
    "        layers = [block(self.in_channels, out_channels, ini_stride)]\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        for _ in range(num_blocks-1):\n",
    "            layers.append(block(self.in_channels, out_channels, 1))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.max_pool(output)\n",
    "        \n",
    "        output = self.conv2_x(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.conv5_x(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#                                          LOSS Part                                           #\n",
    "################################################################################################\n",
    "\n",
    "class Criterion(nn.Module):\n",
    "    def __init__(self, num_classes, eos_coef, losses, \n",
    "                 cost_class: float = 1, cost_bbox: float = 1, cost_giou: float = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # HungarianMatcher loss\n",
    "        self.cost_class = cost_class\n",
    "        self.cost_bbox = cost_bbox\n",
    "        self.cost_giou = cost_giou\n",
    "        assert cost_class != 0 or cost_bbox != 0 or cost_giou != 0, \"all costs cant be 0\"\n",
    "        \n",
    "        # losses names\n",
    "        self.losses = losses\n",
    "        self.num_classes = num_classes  # 91\n",
    "        \n",
    "        # 0-90: classes, 91: no object; lots of bboxs would be no object, so here reduce its loss weight\n",
    "        empty_weight = torch.ones(self.num_classes + 1)\n",
    "        empty_weight[-1] = eos_coef\n",
    "        self.register_buffer('empty_weight', empty_weight)\n",
    "\n",
    "    # all label predicts need loss including no object\n",
    "    def loss_labels(self, outputs: dict, targets: list, indices: list, num_boxes):\n",
    "        assert 'pred_logits' in outputs\n",
    "        \n",
    "        src_logits = outputs['pred_logits']\n",
    "        src_logits = src_logits.view(-1, src_logits.shape[-1])\n",
    "        # torch.Size([3*100, 92])\n",
    "\n",
    "        # get real classes in order w.r.t indices\n",
    "        label = torch.cat([t[\"labels\"][i] for t, (_, i) in zip(targets, indices)])\n",
    "        \n",
    "        # get global idx within batch w.r.t indices\n",
    "        global_idx = torch.cat([src+i*100 for i, (src, _) in enumerate(indices)])\n",
    "        target_classes = torch.full(src_logits.shape[:1], self.num_classes)\n",
    "        target_classes[global_idx] = label\n",
    "\n",
    "        loss_ce = nn.functional.cross_entropy(src_logits, target_classes, self.empty_weight)\n",
    "\n",
    "        return {'loss_ce': loss_ce}\n",
    "\n",
    "    # only boxes that have object need loss\n",
    "    def loss_boxes(self, outputs, targets, indices, num_boxes):\n",
    "        assert 'pred_boxes' in outputs\n",
    "        \n",
    "        # pick out these with object\n",
    "        global_idx = torch.cat([src+i*100 for i, (src, _) in enumerate(indices)])\n",
    "        src_boxes = outputs['pred_boxes']\n",
    "        src_boxes = src_boxes.view(-1, src_boxes.shape[-1])[global_idx]\n",
    "        \n",
    "        # get ground truth bbox w.r.t indices\n",
    "        target_boxes = torch.cat([t['boxes'][i] for t, (_, i) in zip(targets, indices)], dim=0)\n",
    "\n",
    "        loss_bbox = nn.functional.l1_loss(src_boxes, target_boxes, reduction='none')\n",
    "        losses = {'loss_bbox': loss_bbox.sum() / num_boxes}\n",
    "\n",
    "        loss_giou = 1 - self.giou(self.box_cxcywh_to_xyxy(src_boxes), self.box_cxcywh_to_xyxy(target_boxes))\n",
    "        losses['loss_giou'] = loss_giou.sum() / num_boxes\n",
    "        \n",
    "        return losses\n",
    "\n",
    "    def get_loss(self, loss, outputs, targets, indices, num_boxes):\n",
    "        loss_map = {'labels': self.loss_labels, 'boxes': self.loss_boxes}\n",
    "        assert loss in loss_map, f'The {loss} loss not founded.'\n",
    "        \n",
    "        return loss_map[loss](outputs, targets, indices, num_boxes)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "\n",
    "        outputs_without_aux = {k: v for k, v in outputs.items() if k != 'aux_outputs'}\n",
    "\n",
    "        # Retrieve the matching between the outputs of the last layer and the targets\n",
    "        indices = self.hungarian_matcher(outputs_without_aux, targets)\n",
    "\n",
    "        # Compute the average number of target boxes accross all nodes, for normalization purposes\n",
    "        num_boxes = sum(len(t[\"labels\"]) for t in targets)\n",
    "\n",
    "        # Compute all the requested losses\n",
    "        losses = {}\n",
    "        for loss in self.losses:\n",
    "            losses.update(self.get_loss(loss, outputs, targets, indices, num_boxes))\n",
    "        \n",
    "        assert 'aux_outputs' in outputs, \"Auxiliary outputs not founded.\"\n",
    "        \n",
    "        for i, aux_outputs in enumerate(outputs['aux_outputs']):\n",
    "            indices = self.hungarian_matcher(aux_outputs, targets)\n",
    "            for loss in self.losses:\n",
    "                aux_dict = self.get_loss(loss, aux_outputs, targets, indices, num_boxes)\n",
    "                aux_dict = {k + f'_{i}': v for k, v in aux_dict.items()}\n",
    "                losses.update(aux_dict)\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def hungarian_matcher(self, outputs, targets):\n",
    "        bs, num_queries = outputs[\"pred_logits\"].shape[:2]\n",
    "        assert bs == len(targets), f\"Batch {bs} and targets {len(targets)} number not matched.\"\n",
    "\n",
    "        # We flatten to compute the cost matrices in a batch\n",
    "        out_prob = outputs[\"pred_logits\"].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes]\n",
    "        out_bbox = outputs[\"pred_boxes\"].flatten(0, 1)  # [batch_size * num_queries, 4]\n",
    "\n",
    "        # Also concat the target labels and boxes\n",
    "        tgt_ids = torch.cat([v[\"labels\"] for v in targets])\n",
    "        tgt_bbox = torch.cat([v[\"boxes\"] for v in targets])\n",
    "\n",
    "        # classification cost: 1 - proba[target class].\n",
    "        # The 1 is a constant that doesn't change the matching, it can be omitted.\n",
    "        cost_class = -out_prob[:, tgt_ids]\n",
    "\n",
    "        # L1 cost between boxes\n",
    "        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n",
    "\n",
    "        # here should be 1 - giou, but constant doesn't affect matching results, it can be omitted\n",
    "        cost_giou = -self.matrix_giou(self.box_cxcywh_to_xyxy(out_bbox), self.box_cxcywh_to_xyxy(tgt_bbox))\n",
    "\n",
    "        # Final cost matrix\n",
    "        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou\n",
    "        C = C.view(bs, num_queries, -1)\n",
    "        \n",
    "        sizes = [len(v[\"boxes\"]) for v in targets]\n",
    "        # hungarian match\n",
    "        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]\n",
    "        # numpy array 2 tensor\n",
    "        indices = [(torch.as_tensor(i, dtype=torch.int64), \n",
    "                    torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]\n",
    "        # [(torch.Size([21]), torch.Size([21])), (torch.Size([75]), torch.Size([75])), ...]\n",
    "        return indices\n",
    "    \n",
    "    def box_cxcywh_to_xyxy(self, x):\n",
    "        x_c, y_c, w, h = x.unbind(-1)\n",
    "        b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "             (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "        return torch.stack(b, dim=-1)\n",
    "\n",
    "    def matrix_iou(self, boxes1, boxes2):\n",
    "        area1 = box_area(boxes1)\n",
    "        area2 = box_area(boxes2)\n",
    "\n",
    "        lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
    "        rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]\n",
    "\n",
    "        wh = (rb - lt).clamp(min=0)  # [N,M,2]\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n",
    "\n",
    "        union = area1[:, None] + area2 - inter\n",
    "\n",
    "        iou = inter / union\n",
    "        return iou, union\n",
    "\n",
    "    def matrix_giou(self, boxes1, boxes2):\n",
    "        assert (boxes1[:, 2:] >= boxes1[:, :2]).all()\n",
    "        assert (boxes2[:, 2:] >= boxes2[:, :2]).all()\n",
    "        iou, union = self.matrix_iou(boxes1, boxes2)\n",
    "\n",
    "        lt = torch.min(boxes1[:, None, :2], boxes2[:, :2])\n",
    "        rb = torch.max(boxes1[:, None, 2:], boxes2[:, 2:])\n",
    "\n",
    "        wh = (rb - lt).clamp(min=0)  # [N,M,2]\n",
    "        area = wh[:, :, 0] * wh[:, :, 1]\n",
    "\n",
    "        return iou - (area - union) / area\n",
    "    \n",
    "    def iou(self, boxes1, boxes2):\n",
    "        area1 = box_area(boxes1)\n",
    "        area2 = box_area(boxes2)\n",
    "\n",
    "        lt = torch.max(boxes1[:, :2], boxes2[:, :2])\n",
    "        rb = torch.min(boxes1[:, 2:], boxes2[:, 2:])\n",
    "\n",
    "        wh = (rb - lt).clamp(min=0)\n",
    "        inter = wh[:, 0] * wh[:, 1]\n",
    "\n",
    "        union = area1 + area2 - inter\n",
    "\n",
    "        iou = inter / union\n",
    "        return iou, union\n",
    "    \n",
    "    def giou(self, boxes1, boxes2):\n",
    "        assert (boxes1[:, 2:] >= boxes1[:, :2]).all()\n",
    "        assert (boxes2[:, 2:] >= boxes2[:, :2]).all()\n",
    "        iou, union = self.iou(boxes1, boxes2)\n",
    "\n",
    "        lt = torch.min(boxes1[:, :2], boxes2[:, :2])\n",
    "        rb = torch.max(boxes1[:, 2:], boxes2[:, 2:])\n",
    "\n",
    "        wh = (rb - lt).clamp(min=0)\n",
    "        area = wh[:, 0] * wh[:, 1]\n",
    "\n",
    "        return iou - (area - union) / area\n",
    "\n",
    "    \n",
    "################################################################################################\n",
    "#                                          DETR Part                                           #\n",
    "################################################################################################\n",
    "\n",
    "class DETR(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # We take only convolutional layers from ResNet-50 model\n",
    "        self.backbone = ResNet(config.backboneConfig)\n",
    "        self.conv = nn.Conv2d(2048, config.hidden_dim, 1)\n",
    "        self.transformer = Transformer(config.transformerConfig)\n",
    "        \n",
    "        self.queries = nn.Parameter(torch.rand(100, config.hidden_dim))\n",
    "        \n",
    "        self.linear_class = nn.Linear(config.hidden_dim, config.num_classes + 1)\n",
    "        # 3 layers MLP\n",
    "        self.linear_bbox = nn.Sequential(*[nn.Linear(n, k) for n, k in zip([config.hidden_dim]*3, \n",
    "                                                                         [config.hidden_dim]*2+[4])])\n",
    "\n",
    "        # positional encoding\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, config.hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(50, config.hidden_dim // 2))\n",
    "\n",
    "    def forward(self, inputs: list):\n",
    "        assert inputs[0].shape[0] == 3, \"Not supported Channel\"\n",
    "        max_h, max_w = self.find_max_hw(inputs)\n",
    "        inputs, mask = self.preprocess(inputs, max_h, max_w)\n",
    "        \n",
    "        B = inputs.shape[0]\n",
    "        \n",
    "        x = self.backbone(inputs)\n",
    "        h = self.conv(x)\n",
    "        \n",
    "        H, W = h.shape[-2:]\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(0).repeat(B, 1, 1)\n",
    "        # downsample mask\n",
    "        mask = torch.nn.functional.interpolate(mask[None], size=x.shape[-2:])[0].flatten(-2)\n",
    "\n",
    "        h, _, _, _ = self.transformer(h.flatten(2).permute(0, 2, 1),\n",
    "                                      self.queries.unsqueeze(0).repeat(B, 1, 1), mask,\n",
    "                                      pos, self.queries.unsqueeze(0).repeat(B, 1, 1))\n",
    "\n",
    "        logits, bboxes = self.linear_class(h), self.linear_bbox(h).sigmoid()\n",
    "\n",
    "        outputs = {'pred_logits': logits[-1], 'pred_boxes': bboxes[-1]}\n",
    "        outputs['aux_outputs'] = [{'pred_logits': a, 'pred_boxes': b}\n",
    "                                  for a, b in zip(logits[:-1], bboxes[:-1])]\n",
    "        return outputs\n",
    "    \n",
    "    def preprocess(self, inputs, max_h, max_w):\n",
    "        B = len(inputs)\n",
    "        c, dtype = inputs[0].shape[0], inputs[0].dtype\n",
    "\n",
    "        tensor = torch.zeros((B, c, max_h, max_w), dtype=dtype)\n",
    "        mask = torch.zeros((B, max_h, max_w))\n",
    "        for img, pad_img, m in zip(inputs, tensor, mask):\n",
    "            pad_img[:img.shape[0], :img.shape[1], :img.shape[2]].copy_(img)\n",
    "            m[: img.shape[1], :img.shape[2]] = 1\n",
    "\n",
    "        return tensor, mask\n",
    "    \n",
    "    def find_max_hw(self, data):\n",
    "        max_h, max_w = 0, 0\n",
    "        for img in data:\n",
    "            if img.shape[1] > max_h:\n",
    "                max_h = img.shape[1]\n",
    "            if img.shape[2] > max_w:\n",
    "                max_w = img.shape[2]\n",
    "        return max_h, max_w\n",
    "\n",
    "\n",
    "class Resnet50Config:\n",
    "    block = BottleNeck\n",
    "    num_block = [3, 4, 6, 3]\n",
    "\n",
    "class TransformerConfig:\n",
    "    d_model = 256           # embedding Size\n",
    "    d_mlp = 4*d_model       # MLP hidden dimension\n",
    "    d_key = d_value = 32    # dimension of K == Q, V could be different in dot_product_attention\n",
    "    n_layers = 6            # number of Encoder & Decoder Layer\n",
    "    n_heads = 8             # number of heads in Multi-Head Attention\n",
    "    \n",
    "    dropout_rate = 0.1\n",
    "\n",
    "class detrConfig:\n",
    "    num_classes = 91        # classes number\n",
    "    hidden_dim = 256        # embedding dimension\n",
    "    \n",
    "    backboneConfig = Resnet50Config()\n",
    "    transformerConfig = TransformerConfig()\n",
    "\n",
    "model = DETR(detrConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterarion:  1, loss = 66.0089\n",
      "Iterarion:  2, loss = 66.7258\n",
      "5.6567s / iterarion\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "weight_dict = {\n",
    "    'loss_ce': 1, 'loss_bbox': 5, 'loss_giou': 2, 'loss_ce_0': 1, 'loss_bbox_0': 5, 'loss_giou_0': 2, \n",
    "    'loss_ce_1': 1, 'loss_bbox_1': 5, 'loss_giou_1': 2, 'loss_ce_2': 1, 'loss_bbox_2': 5, 'loss_giou_2': 2,\n",
    "    'loss_ce_3': 1, 'loss_bbox_3': 5, 'loss_giou_3': 2, 'loss_ce_4': 1, 'loss_bbox_4': 5, 'loss_giou_4': 2\n",
    "}\n",
    "criterion = Criterion(num_classes=91, eos_coef=0.1, losses=['labels', 'boxes'])\n",
    "\n",
    "batch = 3\n",
    "iterarions = 2\n",
    "begin = time.time()\n",
    "\n",
    "def genData():\n",
    "    return [torch.rand(3, \n",
    "                       torch.randint(350, 500, (1,)).item(),\n",
    "                       torch.randint(200, 500, (1,)).item()) for _ in range(batch-1)] + [torch.rand(3,384,512)]\n",
    "\n",
    "# Training\n",
    "for iterarion in range(iterarions):\n",
    "    optimizer.zero_grad()\n",
    "    targets = [{'boxes':torch.rand(n.item(), 4), \n",
    "                'labels':torch.randint(0, 92, (n.item(),))} for n in torch.randint(1, 100, (batch,))]\n",
    "    \n",
    "    outputs = model(genData())\n",
    "    \n",
    "    loss_dict = criterion(outputs, targets)\n",
    "    losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "    \n",
    "    if iterarion % 1 == 0:\n",
    "        print('Iterarion:', '%2d,' % (iterarion + 1), 'loss =', '{:.4f}'.format(losses))\n",
    "\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "print(f\"{(time.time() - begin)/iterarions:.4f}s / iterarion\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
